{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trax\n",
    "\n",
    "Trax is much more concise. It runs on TensorFlow backend but allows yout to train models with 1 line commands. It also runs end to end. \n",
    "\n",
    "We can focus on learning instead of spending much hours on big frameword implementation. \n",
    "\n",
    "It is good for implementing new SOTA model like Transformers, Reformers, BERT. It is maintined by the Google Brain Team. \n",
    "\n",
    "### Trax based on 2 concepts:\n",
    "- Layers\n",
    "  - Trax layers are simple objects that process data and perform computations. They can be chained together into composite layers using Trax Combinators, allowing to build layers and models of any complexity. \n",
    "- Combinators\n",
    "\n",
    "\n",
    "**Trax:**\n",
    "- It uses Tensorflow as a backend, but it uses JAX library to speed up computations. JAX is an enhanced and optimized version of numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from trax import layers as tl\n",
    "from trax import shapes\n",
    "from trax import fastmath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions are also layers in Trax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial\n",
      "1\n",
      "1\n",
      "-- Inputs --\n",
      "x : [-2 -1  0  1  2] \n",
      "\n",
      "-- Outputs --\n",
      "y : [0 0 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "relu = tl.Relu()\n",
    "\n",
    "print(relu.name)\n",
    "print(relu.n_in)\n",
    "print(relu.n_out)\n",
    "\n",
    "\n",
    "\n",
    "# Inputs\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = relu(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenate\n",
      "2\n",
      "1\n",
      "-- Inputs --\n",
      "x1 : [-10 -20 -30]\n",
      "x2 : [1. 2. 3.] \n",
      "\n",
      "-- Outputs --\n",
      "y : [-10. -20. -30.   1.   2.   3.]\n"
     ]
    }
   ],
   "source": [
    "concat = tl.Concatenate()\n",
    "print(concat.name)\n",
    "print(concat.n_in)\n",
    "print(concat.n_out)\n",
    "\n",
    "\n",
    "# Inputs\n",
    "x1 = np.array([-10, -20, -30])\n",
    "x2 = x1 / -10\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x1 :\", x1)\n",
    "print(\"x2 :\", x2, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = concat([x1, x2])\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)\n",
    "\n",
    "concat2 = tl.Concatenate(n_items=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers can have weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "ShapeDtype{shape:(4,), dtype:float64} <class 'trax.shapes.ShapeDtype'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerlshin/env_ai/lib/python3.10/site-packages/trax/layers/normalization.py:141: UserWarning: Explicitly requested dtype float64 requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  scale = jnp.ones(features, dtype=input_signature.dtype)\n",
      "/home/jerlshin/env_ai/lib/python3.10/site-packages/trax/layers/normalization.py:142: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  bias = jnp.zeros(features, dtype=input_signature.dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('LayerNorm',\n",
       " 1,\n",
       " 1,\n",
       " Array([1., 1., 1., 1.], dtype=float32),\n",
       " Array([0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = tl.LayerNorm()\n",
    "\n",
    "x = np.array([0, 1, 2, 3], dtype=\"float\")\n",
    "\n",
    "# Convert the input datatype from usual tuple to trax ShapeDtype \n",
    "norm.init(shapes.signature(x))\n",
    "\n",
    "print(x.shape)\n",
    "print(shapes.signature(x), type(shapes.signature(x)))\n",
    "\n",
    "norm.name, norm.n_in, norm.n_out, norm.weights[0], norm.weights[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TimesTwo', 1, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TimesTwo():\n",
    "    layer_name = \"TimesTwo\"  # always give the custom layer a name to identify \n",
    "\n",
    "    def func(x):\n",
    "        return x * 2\n",
    "\n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "times_two = TimesTwo()\n",
    "\n",
    "times_two.name, times_two.n_in, times_two.n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinators\n",
    "\n",
    "We can combine layers to build more complex layers. \n",
    "\n",
    "\n",
    "    * Serial Combinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerlshin/env_ai/lib/python3.10/site-packages/trax/layers/normalization.py:141: UserWarning: Explicitly requested dtype int64 requested in ones is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  scale = jnp.ones(features, dtype=input_signature.dtype)\n",
      "/home/jerlshin/env_ai/lib/python3.10/site-packages/trax/layers/normalization.py:142: UserWarning: Explicitly requested dtype int64 requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  bias = jnp.zeros(features, dtype=input_signature.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Serial Model --\n",
      "Serial[\n",
      "  LayerNorm\n",
      "  Serial[\n",
      "    Relu\n",
      "  ]\n",
      "  TimesTwo\n",
      "  Dense_2\n",
      "  Dense_1\n",
      "  LogSoftmax\n",
      "] \n",
      "\n",
      "-- Properties --\n",
      "name : Serial\n",
      "sublayers : [LayerNorm, Serial[\n",
      "  Relu\n",
      "], TimesTwo, Dense_2, Dense_1, LogSoftmax]\n",
      "expected inputs : 1\n",
      "promised outputs : 1\n",
      "weights & biases: ((Array([1, 1, 1, 1, 1], dtype=int32), Array([0, 0, 0, 0, 0], dtype=int32)), ((), (), ()), (), (Array([[-0.792707  , -0.85926765],\n",
      "       [ 0.72052234,  0.6414506 ],\n",
      "       [ 0.6638057 , -0.3427339 ],\n",
      "       [ 0.3194956 , -0.5063189 ],\n",
      "       [-0.3447836 ,  0.52460796]], dtype=float32), Array([ 4.2711878e-07, -1.1384492e-06], dtype=float32)), (Array([[-0.17818879],\n",
      "       [ 0.00781706]], dtype=float32), Array([1.6863944e-06], dtype=float32)), ()) \n",
      "\n",
      "-- Inputs --\n",
      "x : [-2 -1  0  1  2] \n",
      "\n",
      "-- Outputs --\n",
      "y : [0.]\n"
     ]
    }
   ],
   "source": [
    "serial = tl.Serial(\n",
    "    tl.LayerNorm(),\n",
    "    tl.Relu(),\n",
    "    times_two,\n",
    "\n",
    "    tl.Dense(n_units=2),\n",
    "    tl.Dense(n_units=1),\n",
    "    tl.LogSoftmax()\n",
    ")\n",
    "\n",
    "\n",
    "# Initialization\n",
    "x = np.array([-2, -1, 0, 1, 2]) #input\n",
    "serial.init(shapes.signature(x)) #initialising serial instance\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial,\"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"sublayers :\", serial.sublayers)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out)\n",
    "print(\"weights & biases:\", serial.weights, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX\n",
    "\n",
    "Some things are not possible with JAX's fastmat numpy but still possible with regular Nump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numpy = np.array([1, 2, 3])\n",
    "\n",
    "n_jax = fastmath.numpy.array([1,2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Classes and Subclasses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class My_class():\n",
    "    x = None\n",
    "\n",
    "instance = My_class()\n",
    "\n",
    "str(instance.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__init__` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class My_class():\n",
    "    def __init__(self, y):\n",
    "        self.x = y\n",
    "    \n",
    "instance = My_class(10)\n",
    "\n",
    "str(instance.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__call__` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "class My_class():\n",
    "    def __init__(self, y):\n",
    "        self.x = y\n",
    "    \n",
    "    def  __call__(self, z):\n",
    "        self.x += z\n",
    "        print(self.x)\n",
    "    \n",
    "instance = My_class(5)\n",
    "\n",
    "instance(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class My_Class: \n",
    "    def __init__(self, y, z): \n",
    "        self.x_1 = y\n",
    "        self.x_2 = z\n",
    "    def __call__(self):      \n",
    "        a = self.x_1 - 2*self.x_2 \n",
    "        return a\n",
    "    def my_method(self, w):  \n",
    "        result = self.x_1*self.x_2 + w\n",
    "        return result\n",
    "\n",
    "instance = My_Class(1, 10)\n",
    "\n",
    "instance.my_method(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclass and Inheritance\n",
    "\n",
    "\n",
    "`Trax` uses classes and subclassesto define layers. Every layer from the model is defined as a subclass of the layer of base class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For subclass, every method and parameter is inherited from 'super' class including `__init__` and `__call__` \n",
    "'''\n",
    "\n",
    "class sub_c(My_Class):\n",
    "    def additional_method(self):\n",
    "        print(self.x_1)\n",
    "\n",
    "instance = sub_c(1,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators\n",
    "\n",
    "Behaves like a iterator, it will return the next item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "\n",
    "def data_generator(batch, data_x, data_y, shuffle=True):\n",
    "    data_lng = len(data_x)\n",
    "    index_list = [*range(data_lng)] # list with the ordered idexes of sample data\n",
    "\n",
    "    if shuffle:\n",
    "        rnd.shuffle(index_list)\n",
    "    \n",
    "    idex = 0\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for i in range(batch):\n",
    "            if index >= data_lng:\n",
    "                index=0\n",
    "\n",
    "                if shuffe:\n",
    "                    rnd.shuffle(index_list)\n",
    "            \n",
    "            x.append(data_x[index_list[index]])\n",
    "            y.append(data_y[index_list[index]])\n",
    "    \n",
    "        yield (x, y)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
